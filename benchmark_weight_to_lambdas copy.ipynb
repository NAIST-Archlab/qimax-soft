{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thời gian NumPy (CPU): 19.0819 giây\n",
      "Thời gian CuPy (GPU): 0.3014 giây\n",
      "Kết quả giống nhau.\n",
      "Tăng tốc: 63.32x\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "import time\n",
    "\n",
    "# Hàm cũ sử dụng NumPy\n",
    "def weightss_to_lambda_numpy(weightss: np.ndarray, lambdas: np.ndarray) -> np.ndarray:\n",
    "    num_qubits = weightss.shape[1]\n",
    "    new_lambdas = np.zeros((4**num_qubits))\n",
    "    for j, weights in enumerate(weightss):\n",
    "        combinations = np.stack(np.meshgrid(*weights, indexing='ij'), axis=-1).reshape(-1, len(weights))\n",
    "        new_lambdas += lambdas[j] * np.prod(combinations, axis=1)\n",
    "    return new_lambdas\n",
    "\n",
    "# Hàm mới sử dụng CuPy\n",
    "def weightss_to_lambda_cupy(weightss: cp.ndarray, lambdas: cp.ndarray) -> cp.ndarray:\n",
    "    num_terms, num_qubits, _ = weightss.shape\n",
    "    new_lambdas = cp.zeros(4**num_qubits)\n",
    "    for j in range(num_terms):\n",
    "        weights = weightss[j]\n",
    "        products = weights[0]\n",
    "        for k in range(1, num_qubits):\n",
    "            products = cp.outer(products, weights[k]).ravel()\n",
    "        new_lambdas += lambdas[j] * products\n",
    "    return new_lambdas\n",
    "\n",
    "# Thiết lập tham số\n",
    "num_qubits = 10  # 4^10 = 1,048,576 phần tử\n",
    "num_terms = 200\n",
    "\n",
    "# Tạo dữ liệu ngẫu nhiên cho NumPy\n",
    "weightss_np = np.random.rand(num_terms, num_qubits, 4)\n",
    "lambdas_np = np.random.rand(num_terms)\n",
    "\n",
    "# Chuyển dữ liệu sang CuPy\n",
    "weightss_cp = cp.asarray(weightss_np)\n",
    "lambdas_cp = cp.asarray(lambdas_np)\n",
    "\n",
    "# Benchmark hàm NumPy\n",
    "start_time = time.time()\n",
    "result_numpy = weightss_to_lambda_numpy(weightss_np, lambdas_np)\n",
    "numpy_time = time.time() - start_time\n",
    "print(f\"Thời gian NumPy (CPU): {numpy_time:.4f} giây\")\n",
    "\n",
    "# Benchmark hàm CuPy\n",
    "start_time = time.time()\n",
    "result_cupy = weightss_to_lambda_cupy(weightss_cp, lambdas_cp)\n",
    "cupy_time = time.time() - start_time\n",
    "print(f\"Thời gian CuPy (GPU): {cupy_time:.4f} giây\")\n",
    "\n",
    "if np.allclose(result_numpy, result_cupy):\n",
    "    print(\"Kết quả giống nhau.\")\n",
    "else:\n",
    "    print(\"Kết quả khác nhau.\")\n",
    "\n",
    "# Tính tốc độ tăng tốc\n",
    "speedup = numpy_time / cupy_time\n",
    "print(f\"Tăng tốc: {speedup:.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3, 4) (2,)\n",
      "(1, 3, 4) (1,)\n",
      "(1, 3, 4) (1,)\n"
     ]
    }
   ],
   "source": [
    "from gqimax.mapper import weightsss_to_lambdas\n",
    "num_qubits = 3  # 4^10 = 1,048,576 phần tử\n",
    "num_terms = 5\n",
    "ks = [np.random.randint(1, num_terms) for _ in range(num_qubits)]\n",
    "\n",
    "weightsss_np = [cp.random.rand(ks[i], num_qubits, 4) * (cp.random.rand(ks[i], num_qubits, 4) > 0.5) for i in range(num_qubits)]\n",
    "lambdass_np = [cp.random.rand(ks[i]) for i in range(num_qubits)]\n",
    "for i in range(num_qubits):\n",
    "\tprint(weightsss_np[i].shape, lambdass_np[i].shape)\n",
    "mapped_lambdass, non_zeros_indicess = weightsss_to_lambdas(weightsss_np, lambdass_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambdass[0]: [0.00144713 0.00110885 0.00139623 0.00053744]\n",
      "non_zeros_indicess: [ 2  6 10 14]\n",
      "lambdass[1]: [0.17136025 0.3747416  0.18828798 0.41176026 0.09784203 0.21396724]\n",
      "non_zeros_indicess: [ 9 11 41 43 57 59]\n",
      "lambdass[2]: [0.0037968  0.00178773 0.00043901 0.00839594 0.00395323 0.00097079\n",
      " 0.02371438 0.01116593 0.002742   0.05244004 0.02469142 0.00606344]\n",
      "non_zeros_indicess: [ 8  9 11 12 13 15 56 57 59 60 61 63]\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_qubits):\n",
    "\tprint(f\"lambdass[{i}]: {mapped_lambdass[i]}\")\n",
    "\tprint(f\"non_zeros_indicess: {non_zeros_indicess[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hàm wrapper để gọi kernel\n",
    "def cuda_map_cx(words_array, control, target):\n",
    "    \"\"\"\n",
    "    Áp dụng map_cx trên mảng k word bằng CUDA kernel.\n",
    "    Args:\n",
    "        words_array: cp.ndarray shape (k, n), dtype=cp.int8\n",
    "        control: int, chỉ số control\n",
    "        target: int, chỉ số target\n",
    "    Returns:\n",
    "        lambdas: cp.ndarray shape (k,), dtype=cp.int8\n",
    "        new_words_array: cp.ndarray shape (k, n), dtype=cp.int8\n",
    "    \"\"\"\n",
    "    k, n = words_array.shape\n",
    "    new_words_array = cp.empty_like(words_array, dtype=cp.int8)\n",
    "    lambdas = cp.empty(k, dtype=cp.int8)\n",
    "\n",
    "    block_size = 256\n",
    "    grid_size = (k + block_size - 1) // block_size\n",
    "\n",
    "    map_cx_kernel((grid_size,), (block_size,), \n",
    "                  (words_array, new_words_array, lambdas, k, n, control, target))\n",
    "\n",
    "    return lambdas, new_words_array\n",
    "\n",
    "def flatten_ragged_matrix_cupy(ragged_matrix):\n",
    "    lengths = cp.array([len(row) for row in ragged_matrix], dtype=cp.int8)\n",
    "    starts = cp.concatenate((cp.array([0]), cp.cumsum(lengths)), dtype=cp.int8)\n",
    "    flatten_vector = cp.concatenate(ragged_matrix, dtype=cp.int8)\n",
    "    return flatten_vector, starts[:-1]\n",
    "\n",
    "def unflatten_ragged_matrix_cupy(flatten_vector, starts):\n",
    "    return cp.vsplit(flatten_vector, starts[1:].tolist())\n",
    "\n",
    "def map_indices_to_weighted(ragged_lambdas, ragged_tensor, control, target):\n",
    "    \"\"\"\n",
    "    --- First, I encode the n-qubit Pauli word (index) as list of n int8 array\n",
    "    Ex: 0(III) --> [0, 0, 0]\n",
    "    For n-stabilizer, we have n x k indices, so the encoded tensor will be n x k x n (ragged tensor)\n",
    "    Original tensor: [\n",
    "\t\tarray([1, 2]),\n",
    "\t\tarray([3]),\n",
    "\t\tarray([4]),\n",
    "\t]\n",
    "    --- Next step, I flatten this tensor to 1D array (each element is still n-dim array)\n",
    "    Flatten vector: [1,2,3,4] and following starts (variable) = [0, 2, 3]\n",
    "    --- Map this array to the new array using map_indices_to_weighted kernel\n",
    "    Mapped flatten vector: [\n",
    "        [0, 0, 1],\n",
    "        [0, 0, 2],\n",
    "        [0, 0, 3],\n",
    "        [0, 1, 0],\n",
    "    ] (n x k x n)\n",
    "    \n",
    "    --- Finally, I unflatten the mapped array to the original shape (ragged tensor)\n",
    "    --- Obviously, this function requires starts variable (the start index of each row in the flatten vector)\n",
    "    \n",
    "    Out ragged tensor (with starts = [0, 2, 3]): [\n",
    "        array([[0, 0, 1], [0, 0, 2]]),\n",
    "\t\tarray([[0, 0, 3]]),\n",
    "\t\tarray([[0, 1, 0]]),\n",
    "    ]\n",
    "\n",
    "    \"\"\"\n",
    "    flatten_vector, starts = flatten_ragged_matrix_cupy(ragged_tensor)\n",
    "    lambdas_sign, mapped_flatten_vector = cuda_map_cx(flatten_vector, control, target)\n",
    "    starts = starts[1:].tolist()\n",
    "\t# Convert flatten vector to ragged tensor\n",
    "    ragged_tensor = cp.vsplit(mapped_flatten_vector, starts)\n",
    "    lambdas_sign = cp.split(lambdas_sign, starts)\n",
    "\t# OP: lambdas_sign * ragged_lambdas\n",
    "    # This operator can be implemented in CUDA kernel (in file notebook)\n",
    "    # But I see there is no different between two methods\n",
    "    return [cp.multiply(m1, m2) for m1, m2 in zip(ragged_lambdas, lambdas_sign)], ragged_tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2,  6, 10, 14,  9, 11, 41, 43, 57, 59,  8,  9, 11, 12, 13, 15, 56,\n",
       "        57, 59, 60, 61, 63], dtype=int8),\n",
       " array([ 0,  4, 10], dtype=int8))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten_ragged_matrix_cupy(non_zeros_indicess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 2,  6, 10, 14], dtype=int64),\n",
       " array([ 9, 11, 41, 43, 57, 59], dtype=int64),\n",
       " array([ 8,  9, 11, 12, 13, 15, 56, 57, 59, 60, 61, 63], dtype=int64)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_zeros_indicess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "weightsss = cp.array([\n",
    "    [[0,0, 1,4], [1,2,3,4]], \n",
    "    [[0,1,0,0], [1,2,0,0]], \n",
    "    [[1,0,0,4], [0,0, 1,4]]] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.5873697 ,  2.34947881,  0.69422608,  1.38845216,  0.58182811,\n",
       "         1.16365622,  1.74548433,  2.32731244,  2.32731244,  4.65462487,\n",
       "         9.33141613, 18.70716501]),\n",
       " array([ 2,  3,  4,  5,  8,  9, 10, 11, 12, 13, 14, 15], dtype=int64))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from gqimax.mapper import weightss_to_lambda\n",
    "from gqimax.utils import index_to_indices, index_to_word\n",
    "\n",
    "lambdas = weightss_to_lambda(weightsss, lambdass_np[0])\n",
    "lambdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0, 0],\n",
      "       [0, 1],\n",
      "       [0, 2],\n",
      "       [0, 3],\n",
      "       [1, 0],\n",
      "       [1, 1],\n",
      "       [1, 2],\n",
      "       [1, 3],\n",
      "       [2, 0],\n",
      "       [2, 1],\n",
      "       [2, 2],\n",
      "       [2, 3]]), array([[0, 0],\n",
      "       [0, 1],\n",
      "       [0, 2],\n",
      "       [0, 3],\n",
      "       [1, 0],\n",
      "       [1, 1],\n",
      "       [1, 2],\n",
      "       [1, 3],\n",
      "       [2, 0],\n",
      "       [2, 1],\n",
      "       [2, 2],\n",
      "       [2, 3]])]\n"
     ]
    }
   ],
   "source": [
    "indicess = []\n",
    "for i in range(2):\t\n",
    "    indices = cp.nonzero(lambdas)[0]\n",
    "    lambdas = lambdas[indices]\n",
    "    new_indices = []\n",
    "    for index in indices:\n",
    "        new_indices.append(index_to_indices(int(index), 2))\n",
    "    indicess.append(cp.array(new_indices))\n",
    "print(indicess)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
