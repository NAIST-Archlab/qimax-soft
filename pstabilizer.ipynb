{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.experimental import sparse\n",
    "import jax.numpy as jnp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_to_weight(character):\n",
    "    if character == \"x\":\n",
    "        return np.array([0, 1, 0, 0])\n",
    "    if character == \"y\":\n",
    "        return np.array([0, 0, 1, 0])\n",
    "    if character == \"z\":\n",
    "        return np.array([0, 0, 0, 1])\n",
    "    if character == \"i\":\n",
    "        return np.array([1, 0, 0, 0])\n",
    "def char_to_index(character):\n",
    "    if character == \"x\":\n",
    "        return 1\n",
    "    if character == \"y\":\n",
    "        return 2\n",
    "    if character == \"z\":\n",
    "        return 3\n",
    "    if character == \"i\":\n",
    "        return 0\n",
    "    \n",
    "def group_instructorss_by_qubits(nested_list, n):\n",
    "    grouped_data = []\n",
    "    for sublist in nested_list:\n",
    "        groups = {i: [] for i in range(n)}  # Create empty groups for all indices 0 to n\n",
    "        for item in sublist:\n",
    "            key = item[1]  # Second value in the tuple\n",
    "            groups[key].append(item)\n",
    "        grouped_data.append([groups[i] for i in range(n)])  # Append the lists in order\n",
    "    return grouped_data\n",
    "\n",
    "def mapper_noncx(character, instructors):\n",
    "    # Map a single Pauliword to list by multiple instructors\n",
    "    # Example: X -> [0, 1, 0, 0] -- h --> [0,0,-1,0] = -Y\n",
    "    from numpy import sin, cos, sqrt\n",
    "    weights = char_to_weight(character)\n",
    "    for gate, index, param in instructors:\n",
    "        I, A, B, C = weights\n",
    "        if gate == \"h\":\n",
    "            weights = np.array([I, C, -B, A])\n",
    "        if gate == \"s\":\n",
    "            weights = np.array([I, -B, A, C])\n",
    "        if gate == \"t\":\n",
    "            weights = np.array([I, (A - B) / sqrt(2), (A + B) / sqrt(2), C])\n",
    "        if gate == \"rx\":\n",
    "            weights = np.array([I, A, B * cos(param) - C * sin(param), B * sin(param) + C * cos(param)])\n",
    "        if gate == \"ry\":\n",
    "            weights = np.array([I, A * cos(param) + C * sin(param), B, C * cos(param) - A * sin(param)])\n",
    "        if gate == \"rz\":\n",
    "            weights = np.array([I, A * cos(param) - B * sin(param), B * cos(param) + A * sin(param), C])\n",
    "    return weights\n",
    "\n",
    "def construct_LUT_noncx(instructorsss, num_qubits):\n",
    "    # instructorss has size k x n x [?], with k is number of non-cx layer, n is number of qubits, \n",
    "    # ? is the number of instructor.\n",
    "    # lut has size k x n x 4 x 4, with 4 is the number of Pauliword, 4 for weights\n",
    "    k = len(instructorsss)\n",
    "    lut = np.zeros((k, num_qubits, 4, 4))\n",
    "    print(lut.shape)\n",
    "    characters = [\"i\", \"x\", \"y\", \"z\"]\n",
    "    for k in range(k):\n",
    "        for j in range(num_qubits):\n",
    "            for i in range(4):\n",
    "                lut[k][j][i] = mapper_noncx(characters[i], instructorsss[k][j])\n",
    "    return lut\n",
    "\n",
    "class Instructor:\n",
    "    def __init__(self, num_qubits):\n",
    "        self.clusters = []\n",
    "        self.cluster = []\n",
    "        self.cluster_temp = []\n",
    "        self.xcluster = []\n",
    "        self.xcluster_temp = []\n",
    "        self.xclusters = []\n",
    "        self.instructors = []\n",
    "        self.num_qubits = num_qubits\n",
    "        self.barriers = [0] * self.num_qubits\n",
    "        self.is_cx_first = False\n",
    "    def append(self, gate, index, param=0):\n",
    "        self.instructors.append((gate, index, param))\n",
    "\n",
    "    def clustering(self):\n",
    "        if self.instructors[0][0] == \"cx\":\n",
    "            self.is_cx_first = True\n",
    "        self.barriers = [0] * self.num_qubits\n",
    "        while len(self.instructors) > 0:\n",
    "            gate, index, _ = self.instructors[0]\n",
    "            \n",
    "            is_break = False\n",
    "            if gate == \"cx\":\n",
    "                self.barriers[index[0]] += 1\n",
    "                self.barriers[index[1]] += 1\n",
    "                if sum(self.barriers) >= self.num_qubits and np.all(self.barriers):\n",
    "                    if len(self.instructors) > 1:\n",
    "                        if self.instructors[1][0] != \"cx\":\n",
    "                            is_break = True\n",
    "\n",
    "                self.xcluster.append(self.instructors.pop(0))\n",
    "            else:\n",
    "                if self.barriers[index] == 0:\n",
    "                    self.cluster.append(self.instructors.pop(0))\n",
    "                else:\n",
    "                    self.cluster_temp.append(self.instructors.pop(0))\n",
    "            if is_break:\n",
    "                if len(self.cluster) > 0:\n",
    "                    self.clusters.append(self.cluster)\n",
    "                self.instructors =  self.cluster_temp + self.instructors\n",
    "                if len(self.xcluster) > 0:\n",
    "                    self.xclusters.append(self.xcluster)\n",
    "                self.cluster = []\n",
    "                self.cluster_temp = []\n",
    "                self.xcluster = []\n",
    "                self.barriers = [0] * self.num_qubits\n",
    "                is_break = False\n",
    "        if len(self.cluster) > 0:\n",
    "            self.clusters.append(self.cluster)\n",
    "        if len(self.cluster_temp) > 0:\n",
    "            self.clusters.append(self.cluster_temp)\n",
    "        if len(self.xcluster) > 0:\n",
    "            self.xclusters.append(self.xcluster)\n",
    "        return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "3\n",
      "(5, 3, 4, 4)\n"
     ]
    }
   ],
   "source": [
    "grouped_instructorss = group_instructorss_by_qubits(ins.clusters, ins.num_qubits)\n",
    "print(len(grouped_instructorss))\n",
    "print(len(grouped_instructorss[0]))\n",
    "# lut has size k x n x 4 x 4\n",
    "LUT = construct_LUT_noncx(grouped_instructorss, ins.num_qubits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [['z','i', 'i']]\n",
    "num_qubits = 3\n",
    "k = 0\n",
    "# Init\n",
    "# 2**n is th\n",
    "lambdas = np.zeros((2**num_qubits))\n",
    "weightss = np.zeros((2**num_qubits, num_qubits, 4))\n",
    "for w, word in enumerate(words):\n",
    "    for j, char in enumerate(word):\n",
    "        index = char_to_index(char)\n",
    "        weightss[w][j] = LUT[k][j][index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 3, 4)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weightss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.74383163, -0.00105933,  0.6683662 ],\n",
       "       [ 1.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 1.        ,  0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weightss[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.  6.  9. 12.  6. 12. 18. 24.  9. 18. 27. 36. 12. 24. 36. 48.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the input list\n",
    "weightss = np.array([[[1,2,3,4], [1,2,3,4]], [[1,2,3,4], [1,2,3,4]], [[1,2,3,4], [1,2,3,4]]])\n",
    "\n",
    "def weightss_to_list(weightss: np.ndarray) -> np.ndarray:\n",
    "    # A sum of transformed word (a matrix 4^n x n x 4) to list\n",
    "    # Example for a single transformed word: [[1,2,3,4], [1,2,3,4]] -> [1, 2, 3, 4, 2, 4, 6, 8, 3, 6, 9, 12, 4, 8, 12, 16]\n",
    "    # Example for this function (sum, 2 qubits, 3 term):\n",
    "    # [[[1,2,3,4], [1,2,3,4]], [[1,2,3,4], [1,2,3,4]], [[1,2,3,4], [1,2,3,4]]] -> [ 3.  6.  9. 12.  6. 12. 18. 24.  9. 18. 27. 36. 12. 24. 36. 48.]\n",
    "    num_qubits = weightss.shape[1]\n",
    "    lists = np.zeros((4**num_qubits))\n",
    "    for weights in weightss:\n",
    "        combinations = np.array(np.meshgrid(*weights)).T.reshape(-1, len(weights))\n",
    "        lists += np.prod(combinations, axis=1)\n",
    "    return lists\n",
    "\n",
    "print(weightss_to_list(weightss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ins = Instructor(4)\n",
    "ins.append(\"h\", 0)\n",
    "ins.append(\"rx\", 1, 0.78)\n",
    "ins.append(\"h\", 2)\n",
    "ins.append(\"h\", 0)\n",
    "ins.append(\"cx\", [0, 1])\n",
    "ins.append(\"h\", 2)\n",
    "ins.append(\"h\", 2)\n",
    "ins.append(\"ry\", 0, 0.56)\n",
    "ins.append(\"cx\", [1, 2])\n",
    "ins.append(\"h\", 1)\n",
    "ins.append(\"h\", 3)\n",
    "ins.append(\"h\", 3)\n",
    "ins.append(\"h\", 3)\n",
    "ins.append(\"h\", 3)\n",
    "ins.append(\"h\", 0)\n",
    "ins.append(\"h\", 1)\n",
    "ins.append(\"h\", 2)\n",
    "ins.append(\"h\", 3)\n",
    "ins.append(\"h\", 0)\n",
    "ins.append(\"h\", 2)\n",
    "ins.append(\"cx\", [1, 3])\n",
    "ins.clustering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['cx', [0, 1], 0], ['cx', [1, 2], 0], ['cx', [1, 3], 0]]]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ins.xclusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_qubits = 3\n",
    "ins = Instructor(num_qubits)\n",
    "for k in range(5):\n",
    "\tfor i in range(num_qubits - 1):\n",
    "\t\tins.append('cx', [i, i + 1])\n",
    "\tins.append('cx', [num_qubits - 1, 0])\n",
    "\tfor i in range(num_qubits):\n",
    "\t\tins.append('rx', i, np.random.rand())\n",
    "\t\tins.append('ry', i, np.random.rand())\n",
    "\t\tins.append('rz', i, np.random.rand())\n",
    "\n",
    "ins.clustering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('rx', 0, 0.4792542746758992),\n",
       "  ('ry', 0, 0.7178444895678454),\n",
       "  ('rz', 0, 0.6672183370132274),\n",
       "  ('rx', 1, 0.3857606257923717),\n",
       "  ('ry', 1, 0.47369881398055047),\n",
       "  ('rz', 1, 0.6356524803973157),\n",
       "  ('rx', 2, 0.6452497698710842),\n",
       "  ('ry', 2, 0.05358075830677966),\n",
       "  ('rz', 2, 0.5552902363142603)],\n",
       " [('rx', 0, 0.7508895716449558),\n",
       "  ('ry', 0, 0.057178737245975775),\n",
       "  ('rz', 0, 0.9585677579132423),\n",
       "  ('rx', 1, 0.07390337892847842),\n",
       "  ('ry', 1, 0.6932453586154507),\n",
       "  ('rz', 1, 0.0805802781623427),\n",
       "  ('rx', 2, 0.9825872991886534),\n",
       "  ('ry', 2, 0.7598410714091143),\n",
       "  ('rz', 2, 0.4896800116532498)],\n",
       " [('rx', 0, 0.483682710074266),\n",
       "  ('ry', 0, 0.36531156600046577),\n",
       "  ('rz', 0, 0.9249046303216883),\n",
       "  ('rx', 1, 0.7128800333121091),\n",
       "  ('ry', 1, 0.5220985559609234),\n",
       "  ('rz', 1, 0.4276898755870977),\n",
       "  ('rx', 2, 0.730625286556946),\n",
       "  ('ry', 2, 0.18326635869828733),\n",
       "  ('rz', 2, 0.5948723009116327)],\n",
       " [('rx', 0, 0.011420802533366525),\n",
       "  ('ry', 0, 0.7236273729322115),\n",
       "  ('rz', 0, 0.26383164372609025),\n",
       "  ('rx', 1, 0.9484543054073168),\n",
       "  ('ry', 1, 0.6782661804180243),\n",
       "  ('rz', 1, 0.12068569481725122),\n",
       "  ('rx', 2, 0.8634401617280325),\n",
       "  ('ry', 2, 0.6347927748201808),\n",
       "  ('rz', 2, 0.95092674820622)],\n",
       " [('rx', 0, 0.1621838159724014),\n",
       "  ('ry', 0, 0.2768520454044182),\n",
       "  ('rz', 0, 0.4903770909479469),\n",
       "  ('rx', 1, 0.007268369910095718),\n",
       "  ('ry', 1, 0.12678169552252117),\n",
       "  ('rz', 1, 0.9690743834134278),\n",
       "  ('rx', 2, 0.8421890831876637),\n",
       "  ('ry', 2, 0.20236336305683833),\n",
       "  ('rz', 2, 0.4411132939532293)]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ins.clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('cx', [0, 1], 0), ('cx', [1, 2], 0), ('cx', [2, 0], 0)],\n",
       " [('cx', [0, 1], 0), ('cx', [1, 2], 0), ('cx', [2, 0], 0)],\n",
       " [('cx', [0, 1], 0), ('cx', [1, 2], 0), ('cx', [2, 0], 0)],\n",
       " [('cx', [0, 1], 0), ('cx', [1, 2], 0), ('cx', [2, 0], 0)],\n",
       " [('cx', [0, 1], 0), ('cx', [1, 2], 0), ('cx', [2, 0], 0)]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ins.xclusters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
