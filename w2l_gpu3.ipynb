{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total execution time for 10 jobs: 0.1055 seconds\n"
     ]
    }
   ],
   "source": [
    "import cupy as cp\n",
    "import time\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# CUDA kernel for base-4 encoding (pre-compiled only once)\n",
    "# -------------------------------------------------------------------\n",
    "base4_kernel = cp.RawKernel(r'''\n",
    "extern \"C\" __global__\n",
    "void encode_base4_all(\n",
    "    const int* shapes,        \n",
    "    const int* data,          \n",
    "    const int* offsets,        \n",
    "    const int* offsets_result, \n",
    "    const int* powers,         \n",
    "    int* output,               \n",
    "    int N,                    \n",
    "    int n_dim,               \n",
    "    int total_size             \n",
    ") {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx >= total_size) return;\n",
    "\n",
    "    int i = 0;\n",
    "    while (i < N - 1 && idx >= offsets_result[i + 1]) i++;\n",
    "    int local_idx = idx - offsets_result[i];\n",
    "\n",
    "    int temp = local_idx;\n",
    "    int indices[3]; \n",
    "    for (int j = n_dim - 1; j >= 0; j--) {\n",
    "        int s = shapes[i * n_dim + j];\n",
    "        indices[j] = temp % s;\n",
    "        temp /= s;\n",
    "    }\n",
    "\n",
    "    int acc = 0;\n",
    "    for (int j = 0; j < n_dim; j++) {\n",
    "        int offset = offsets[i * n_dim + j];\n",
    "        int index = indices[j];\n",
    "        acc += data[offset + index] * powers[j];\n",
    "    }\n",
    "    output[idx] = acc;\n",
    "}\n",
    "''', 'encode_base4_all')\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Data preparation helper function\n",
    "# -------------------------------------------------------------------\n",
    "def prepare_data(arrayss):\n",
    "    \"\"\"\n",
    "    Prepares input data for the encode_base4_all kernel.\n",
    "    \n",
    "    Parameters:\n",
    "      arrayss: A list of arrays (each job) where each job is a list of cp.ndarray.\n",
    "               Each inner list represents a multi-dimension set of arrays.\n",
    "               \n",
    "    Returns:\n",
    "      shapes, data, offsets, offsets_result, powers, sizes\n",
    "    \"\"\"\n",
    "    N = len(arrayss)           # Number of batches in the job\n",
    "    n_dim = len(arrayss[0])    # Number of dimensions per batch item\n",
    "\n",
    "    # Build shapes from the lengths of each array\n",
    "    shapes = cp.array([len(arr) for arrays in arrayss for arr in arrays], dtype=cp.int32)\n",
    "\n",
    "    # Concatenate data arrays into one large array\n",
    "    data = cp.concatenate([arr for arrays in arrayss for arr in arrays])\n",
    "\n",
    "    # Compute the offset for each array in the flattened data\n",
    "    lengths = shapes.reshape(N, n_dim)\n",
    "    offsets = cp.cumsum(cp.concatenate([cp.array([0], dtype=cp.int32), lengths.flatten()[:-1]]))\n",
    "\n",
    "    # Compute the total number of elements for each batch and the result offsets\n",
    "    sizes = cp.prod(lengths.reshape(N, n_dim), axis=1)\n",
    "    offsets_result = cp.cumsum(cp.concatenate([cp.array([0], dtype=cp.int32), sizes[:-1]]))\n",
    "\n",
    "    # Pre-calculate weights (powers of 4) for each dimension: 4^(n_dim-1), ..., 4^0.\n",
    "    powers = cp.array([4 ** (n_dim - i - 1) for i in range(n_dim)], dtype=cp.int32)\n",
    "\n",
    "    return shapes, data, offsets, offsets_result, powers, sizes\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Original function to encode arrays to base-4 on the GPU\n",
    "# -------------------------------------------------------------------\n",
    "def encode_base4s_gpu(arrayss):\n",
    "    \"\"\"\n",
    "    Encode base-4 for all batches in arrayss using a CUDA kernel.\n",
    "    \n",
    "    Parameters:\n",
    "      arrayss: List of batch items, each batch item is a list of cp.ndarray.\n",
    "      \n",
    "    Returns:\n",
    "      A tuple (output, offsets_result) where output is the flattened encoded result.\n",
    "    \"\"\"\n",
    "    shapes, data, offsets, offsets_result, powers, sizes = prepare_data(arrayss)\n",
    "    N = len(arrayss)\n",
    "    n_dim = len(arrayss[0])\n",
    "    total_size = int(sizes.sum())\n",
    "\n",
    "    output = cp.empty(total_size, dtype=cp.int32)\n",
    "    threads_per_block = 256\n",
    "    blocks_per_grid = (total_size + threads_per_block - 1) // threads_per_block\n",
    "\n",
    "    base4_kernel((blocks_per_grid,), (threads_per_block,),\n",
    "                 (shapes, data, offsets, offsets_result, powers, output, N, n_dim, total_size))\n",
    "    return output, offsets_result\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Optimized batched version using asynchronous streams\n",
    "# -------------------------------------------------------------------\n",
    "def run_batch_encode_base4s_gpu_optimized(arrayss_list):\n",
    "    \"\"\"\n",
    "    Run multiple encode_base4s_gpu jobs concurrently on the GPU.\n",
    "    \n",
    "    Parameters:\n",
    "      arrayss_list: List of arrayss variables (each representing one job)\n",
    "                    where each arrayss is a list of batch items (list of cp.ndarray).\n",
    "                    \n",
    "    Returns:\n",
    "      results: List of lists for each job. Each job's result is a list of encoded arrays\n",
    "               (obtained after splitting the flattened output using offsets_result).\n",
    "    \"\"\"\n",
    "    n_jobs = len(arrayss_list)\n",
    "    # Create one non-blocking stream per job.\n",
    "    streams = [cp.cuda.Stream(non_blocking=True) for _ in range(n_jobs)]\n",
    "    results = [None] * n_jobs\n",
    "\n",
    "    for i, arrayss in enumerate(arrayss_list):\n",
    "        with streams[i]:\n",
    "            shapes, data, offsets, offsets_result, powers, sizes = prepare_data(arrayss)\n",
    "            N = len(arrayss)\n",
    "            n_dim = len(arrayss[0])\n",
    "            total_size = int(sizes.sum())\n",
    "\n",
    "            # Allocate output array on GPU.\n",
    "            output = cp.empty(total_size, dtype=cp.int32)\n",
    "            threads_per_block = 256\n",
    "            blocks_per_grid = (total_size + threads_per_block - 1) // threads_per_block\n",
    "\n",
    "            # Launch the kernel asynchronously in the current stream.\n",
    "            base4_kernel((blocks_per_grid,), (threads_per_block,),\n",
    "                         (shapes, data, offsets, offsets_result, powers, output, N, n_dim, total_size))\n",
    "            \n",
    "            # Split the flattened result into separate arrays using the calculated offsets.\n",
    "            results[i] = cp.split(output, offsets_result[1:].tolist())\n",
    "\n",
    "    # Synchronize all streams to make sure all jobs are finished.\n",
    "    for stream in streams:\n",
    "        stream.synchronize()\n",
    "\n",
    "    return results\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Example usage of the optimized batched function\n",
    "# -------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Let's say we want to run 10 jobs concurrently.\n",
    "    n_jobs = 10\n",
    "\n",
    "    # Prepare a list of arrayss for each job.\n",
    "    # Each job has 5000 batch items and each batch item is a list of 4 arrays.\n",
    "    arrayss_list = [\n",
    "        [\n",
    "            [cp.array([1, 2, 3], dtype=cp.int32), \n",
    "             cp.array([1], dtype=cp.int32), \n",
    "             cp.array([2, 3], dtype=cp.int32),\n",
    "             cp.array([1, 3], dtype=cp.int32)]\n",
    "            for _ in range(5000)\n",
    "        ]\n",
    "        for _ in range(n_jobs)\n",
    "    ]\n",
    "\n",
    "    start = time.time()\n",
    "    all_results = run_batch_encode_base4s_gpu_optimized(arrayss_list)\n",
    "    # cp.cuda.Stream.null.synchronize()  # Ensure completion of all asynchronous jobs\n",
    "    print(\"Total execution time for {} jobs: {:.4f} seconds\".format(n_jobs, time.time() - start))\n",
    "\n",
    "    # For example, access the results of the first job.\n",
    "    # all_results[0] is a list, where each element corresponds to one batch's encoded array.\n",
    "    # Uncomment below to verify shapes for the first 3 batches:\n",
    "    # for i, res in enumerate(all_results):\n",
    "    #     print(f\"Job 0, batch {i}: {res}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
