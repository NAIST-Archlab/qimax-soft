{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambdas: [1 1]\n",
      "New words array: [[0 1 2]\n",
      " [2 3 3]]\n"
     ]
    }
   ],
   "source": [
    "import cupy as cp\n",
    "\n",
    "def vectorized_map_cx(words_array, control, target):\n",
    "    \"\"\"\n",
    "    Áp dụng hàm map_cx trên mảng k word sử dụng CuPy và CUDA.\n",
    "    Args:\n",
    "        words_array: cp.ndarray shape (k, n), dtype=cp.int8, giá trị 0-3\n",
    "        control: int, chỉ số control (0 <= control < n)\n",
    "        target: int, chỉ số target (0 <= target < n)\n",
    "    Returns:\n",
    "        lambdas: cp.ndarray shape (k,), dtype=cp.int8, giá trị 1 hoặc -1\n",
    "        new_words_array: cp.ndarray shape (k, n), dtype=cp.int8, mảng sau biến đổi\n",
    "    \"\"\"\n",
    "    # Bảng tra cứu\n",
    "    new_control_table = cp.array([\n",
    "        [0, 0, 3, 3],\n",
    "        [1, 1, 2, 2],\n",
    "        [2, 2, 1, 1],\n",
    "        [3, 3, 0, 0]\n",
    "    ], dtype=cp.int8)\n",
    "    \n",
    "    new_target_table = cp.array([\n",
    "        [0, 1, 2, 3],\n",
    "        [1, 0, 3, 2],\n",
    "        [1, 2, 3, 2],\n",
    "        [0, 1, 2, 3]\n",
    "    ], dtype=cp.int8)\n",
    "    \n",
    "    lambda_table = cp.array([\n",
    "        [1, 1, 1, 1],\n",
    "        [1, 1, 1, -1],\n",
    "        [1, 1, -1, 1],\n",
    "        [1, 1, 1, 1]\n",
    "    ], dtype=cp.int8)\n",
    "\n",
    "    # Trích xuất giá trị tại control và target\n",
    "    control_values = words_array[:, control]\n",
    "    target_values = words_array[:, target]\n",
    "\n",
    "    # Tra cứu giá trị mới\n",
    "    new_control_values = new_control_table[control_values, target_values]\n",
    "    new_target_values = new_target_table[control_values, target_values]\n",
    "    lambdas = lambda_table[control_values, target_values]\n",
    "\n",
    "    # Cập nhật mảng\n",
    "    new_words_array = words_array.copy()\n",
    "    new_words_array[:, control] = new_control_values\n",
    "    new_words_array[:, target] = new_target_values\n",
    "\n",
    "    return lambdas, new_words_array\n",
    "\n",
    "# Ví dụ sử dụng\n",
    "words_array = cp.array([\n",
    "    [0, 1, 2],  # \"ixy\"\n",
    "    [1, 2, 3]   # \"xyz\"\n",
    "], dtype=cp.int8)\n",
    "control, target = 0, 1\n",
    "lambdas, new_words_array = vectorized_map_cx(words_array, control, target)\n",
    "print(\"Lambdas:\", lambdas)           # [1, 1]\n",
    "print(\"New words array:\", new_words_array)  # [[0, 1, 2], [1, 0, 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambdas: [ 1  1  1  1  1 -1  1  1]\n",
      "New words array: [[0 1 3]\n",
      " [1 2 0]\n",
      " [3 1 1]\n",
      " [2 2 3]\n",
      " [3 0 1]\n",
      " [1 3 3]\n",
      " [0 3 1]\n",
      " [0 3 3]]\n"
     ]
    }
   ],
   "source": [
    "import cupy as cp\n",
    "\n",
    "# Định nghĩa kernel CUDA\n",
    "map_cx_kernel = cp.RawKernel(r'''\n",
    "extern \"C\" __global__\n",
    "void map_cx_kernel(\n",
    "    const char* words_array,  \n",
    "    char* new_words_array,     \n",
    "    char* lambdas,            \n",
    "    int k,                    \n",
    "    int n,              \n",
    "    int control,                \n",
    "    int target                 \n",
    ") {\n",
    "    // Lookup tables\n",
    "    const char new_control_table[4][4] = {\n",
    "        {0, 0, 3, 3},\n",
    "        {1, 1, 2, 2},\n",
    "        {2, 2, 1, 1},\n",
    "        {3, 3, 0, 0}\n",
    "    };\n",
    "    const char new_target_table[4][4] = {\n",
    "        {0, 1, 2, 3},\n",
    "        {1, 0, 3, 2},\n",
    "        {1, 2, 3, 2},\n",
    "        {0, 1, 2, 3}\n",
    "    };\n",
    "    const char lambda_table[4][4] = {\n",
    "        {1, 1, 1, 1},\n",
    "        {1, 1, 1, -1},\n",
    "        {1, 1, -1, 1},\n",
    "        {1, 1, 1, 1}\n",
    "    };\n",
    "\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    if (idx >= k) return;\n",
    "\n",
    "    int offset = idx * n;\n",
    "\n",
    "    for (int i = 0; i < n; i++) {\n",
    "        new_words_array[offset + i] = words_array[offset + i];\n",
    "    }\n",
    "\n",
    "    char control_val = words_array[offset + control];\n",
    "    char target_val = words_array[offset + target];\n",
    "\n",
    "    new_words_array[offset + control] = new_control_table[control_val][target_val];\n",
    "    new_words_array[offset + target] = new_target_table[control_val][target_val];\n",
    "    lambdas[idx] = lambda_table[control_val][target_val];\n",
    "}\n",
    "''', 'map_cx_kernel')\n",
    "\n",
    "# Hàm wrapper để gọi kernel\n",
    "def cuda_map_cx(words_array, control, target):\n",
    "    \"\"\"\n",
    "    Áp dụng map_cx trên mảng k word bằng CUDA kernel.\n",
    "    Args:\n",
    "        words_array: cp.ndarray shape (k, n), dtype=cp.int8\n",
    "        control: int, chỉ số control\n",
    "        target: int, chỉ số target\n",
    "    Returns:\n",
    "        lambdas: cp.ndarray shape (k,), dtype=cp.int8\n",
    "        new_words_array: cp.ndarray shape (k, n), dtype=cp.int8\n",
    "    \"\"\"\n",
    "    k, n = words_array.shape\n",
    "    new_words_array = cp.empty_like(words_array, dtype=cp.int8)\n",
    "    lambdas = cp.empty(k, dtype=cp.int8)\n",
    "\n",
    "    block_size = 256\n",
    "    grid_size = (k + block_size - 1) // block_size\n",
    "\n",
    "    map_cx_kernel((grid_size,), (block_size,), \n",
    "                  (words_array, new_words_array, lambdas, k, n, control, target))\n",
    "\n",
    "    return lambdas, new_words_array\n",
    "\n",
    "words_array = cp.array([\n",
    "[0, 1, 3],\n",
    " [2 ,3, 0],\n",
    " [3, 1, 1],\n",
    " [2, 1 ,3],\n",
    " [3 ,0, 1],\n",
    " [2, 2 ,3],\n",
    " [3, 3 ,1],\n",
    " [3 ,3, 3]\n",
    "], dtype=cp.int8)\n",
    "control, target = 0, 1\n",
    "lambdas, new_words_array = cuda_map_cx(words_array, control, target)\n",
    "print(\"Lambdas:\", lambdas)           # [1, 1]\n",
    "print(\"New words array:\", new_words_array)  # [[0, 1, 2], [1, 0, 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "ragged_tensor = [\n",
    "\tcp.array([[0, 1, 2],[0, 2, 2], [0, 3, 2]], dtype=cp.int8), \n",
    "\tcp.array([[1, 2, 3]], dtype=cp.int8), \n",
    "\tcp.array([[2, 3, 1], [2,2,1]], dtype=cp.int8)    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_ragged_matrix_cupy(ragged_matrix):\n",
    "    lengths = cp.array([len(row) for row in ragged_matrix], dtype=cp.int8)\n",
    "    starts = cp.concatenate((cp.array([0]), cp.cumsum(lengths)), dtype=cp.int8)\n",
    "    flatten_vector = cp.concatenate(ragged_matrix, dtype=cp.int8)\n",
    "    return flatten_vector, starts[:-1]\n",
    "\n",
    "def unflatten_ragged_matrix_cupy(flatten_vector, starts):\n",
    "    return cp.vsplit(flatten_vector, starts[1:].tolist())\n",
    "\n",
    "def map_cx(ragged_lambdas, ragged_tensor, control, target):\n",
    "\tflatten_vector, starts = flatten_ragged_matrix_cupy(ragged_tensor)\n",
    "\n",
    "\tlambdas_sign, mapped_flatten_vector = cuda_map_cx(flatten_vector, control, target)\n",
    "\n",
    "\tstarts = starts[1:].tolist()\n",
    " \n",
    "\t# Convert flatten vector to ragged tensor\n",
    "\tragged_tensor = cp.vsplit(mapped_flatten_vector, starts)\n",
    "\tlambdas_sign = cp.split(lambdas_sign, starts)\n",
    "\t# lambdas_sign * ragged_lambdas\n",
    "\treturn [cp.multiply(m1, m2) for m1, m2 in zip(ragged_lambdas, lambdas_sign)], ragged_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lambdas = [\n",
    "    cp.array([2, 3.5, 1]),\n",
    "    cp.array([1]),\n",
    "    cp.array([1, 1j])\n",
    "]\n",
    "lambdas_out, tensor_out = map_cx(lambdas, ragged_tensor, control, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([2. , 3.5, 1. ]), array([1], dtype=int32), array([ 1.+0.j, -0.-1.j])]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambdas_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0, 1, 2],\n",
       "        [3, 2, 2],\n",
       "        [3, 3, 2]], dtype=int8),\n",
       " array([[2, 3, 3]], dtype=int8),\n",
       " array([[1, 2, 1],\n",
       "        [1, 3, 1]], dtype=int8)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flatten vector: [[0 1 2]\n",
      " [0 2 2]\n",
      " [0 3 2]\n",
      " [1 2 3]\n",
      " [2 3 1]\n",
      " [2 2 1]]\n",
      "Mapped flatten vector: [[0 1 2]\n",
      " [3 2 2]\n",
      " [3 3 2]\n",
      " [2 3 3]\n",
      " [1 2 1]\n",
      " [1 3 1]]\n",
      "[ 1  1  1  1  1 -1]\n",
      "[0 3 4]\n",
      "[array([[0, 1, 2],\n",
      "       [3, 2, 2],\n",
      "       [3, 3, 2]], dtype=int8), array([[2, 3, 3]], dtype=int8), array([[1, 2, 1],\n",
      "       [1, 3, 1]], dtype=int8)]\n"
     ]
    }
   ],
   "source": [
    "import cupy as cp\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "flatten_vector, starts = flatten_ragged_matrix_cupy(ragged_tensor)\n",
    "print(\"Flatten vector:\", flatten_vector)\n",
    "lambdas, mapped_flatten_vector = cuda_map_cx(flatten_vector, 0, 1)\n",
    "print(\"Mapped flatten vector:\", mapped_flatten_vector)\n",
    "print(lambdas)\n",
    "matrix = unflatten_ragged_matrix_cupy(mapped_flatten_vector, starts)\n",
    "print(starts)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running benchmark...\n",
      "Time without CUDA kernel: 0.000000 seconds\n",
      "Time with CUDA kernel: 0.000000 seconds\n"
     ]
    }
   ],
   "source": [
    "import cupy as cp\n",
    "import time\n",
    "import random\n",
    "\n",
    "# Define the CUDA kernel for element-wise multiplication\n",
    "elementwise_mult_kernel = cp.RawKernel(r'''\n",
    "extern \"C\" __global__\n",
    "void elementwise_mult(const char* a, const char* b, char* c, \n",
    "                      const int* lengths, const int n_rows) {\n",
    "    int row = blockIdx.x;  // Each block handles one row\n",
    "    if (row >= n_rows) return;\n",
    "\n",
    "    int len = lengths[row];  // Length of the current row\n",
    "    int tid = threadIdx.x;   // Thread index within the block\n",
    "\n",
    "    if (tid < len) {\n",
    "        c[row * len + tid] = a[row * len + tid] * b[row * len + tid];\n",
    "    }\n",
    "}\n",
    "''', 'elementwise_mult')\n",
    "\n",
    "# Generate large ragged matrices\n",
    "n_rows = 3  # Number of rows\n",
    "max_length = 5  # Maximum length of a row\n",
    "matrix1 = []\n",
    "matrix2 = []\n",
    "lengths = []\n",
    "\n",
    "for _ in range(n_rows):\n",
    "    length = random.randint(1, max_length)  # Random length for each row\n",
    "    lengths.append(length)\n",
    "    matrix1.append(cp.array([random.randint(-127, 127) for _ in range(length)], dtype=cp.int8))\n",
    "    matrix2.append(cp.array([random.randint(-127, 127) for _ in range(length)], dtype=cp.int8))\n",
    "\n",
    "lengths = cp.array(lengths, dtype=cp.int32)\n",
    "\n",
    "# Method 1: Without CUDA Kernel (using cp.multiply)\n",
    "def multiply_without_kernel(matrix1, matrix2):\n",
    "    start_time = time.time()\n",
    "    result = [cp.multiply(m1, m2) for m1, m2 in zip(matrix1, matrix2)]\n",
    "    end_time = time.time()\n",
    "    return result, end_time - start_time\n",
    "\n",
    "# Method 2: With CUDA Kernel\n",
    "def multiply_with_kernel(matrix1, matrix2, lengths):\n",
    "    flat_matrix1 = cp.concatenate(matrix1)\n",
    "    flat_matrix2 = cp.concatenate(matrix2)\n",
    "    result = cp.zeros_like(flat_matrix1)\n",
    "\n",
    "    start_time = time.time()\n",
    "    block_size = 256\n",
    "    grid_size = n_rows\n",
    "    elementwise_mult_kernel((grid_size,), (block_size,), \n",
    "                            (flat_matrix1, flat_matrix2, result, lengths, n_rows))\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Split result back into ragged form (optional, excluded from timing)\n",
    "    result_split = []\n",
    "    offset = 0\n",
    "    for length in lengths.get():\n",
    "        result_split.append(result[offset:offset + length].copy())\n",
    "        offset += length\n",
    "\n",
    "    return result_split, end_time - start_time\n",
    "\n",
    "# Run benchmarks\n",
    "print(\"Running benchmark...\")\n",
    "result_no_kernel, time_no_kernel = multiply_without_kernel(matrix1, matrix2)\n",
    "result_kernel, time_kernel = multiply_with_kernel(matrix1, matrix2, lengths)\n",
    "# Print results\n",
    "print(f\"Time without CUDA kernel: {time_no_kernel:.6f} seconds\")\n",
    "print(f\"Time with CUDA kernel: {time_kernel:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([  -8, -102,   -4,  -34,  -20], dtype=int8),\n",
       " array([ 88,  43, 112,  96,  26], dtype=int8),\n",
       " array([40, 96], dtype=int8)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_no_kernel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
